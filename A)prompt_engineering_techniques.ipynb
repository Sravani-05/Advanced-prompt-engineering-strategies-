{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sravani-05/Advanced-prompt-engineering-strategies-/blob/main/A)prompt_engineering_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDqwh2JzEIFt",
        "outputId": "78e2e3aa-2e43-48c4-f76f-b4575fec807c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "api_key = \"sk-\""
      ],
      "metadata": {
        "id": "ULwmBpUlEK4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ICL**"
      ],
      "metadata": {
        "id": "plSVuIUcETu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success case"
      ],
      "metadata": {
        "id": "PVgVuPDBEyp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a travel assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Best places to visit in december.\"}\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1p1oHP6ERy5",
        "outputId": "0ba107c5-0fce-431c-dc2c-55191af5413c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are many incredible destinations to visit in December. Here are some of the best places to consider:\n",
            "\n",
            "1. Lapland, Finland: Experience the magical winter wonderland of Lapland, where you can see the Northern Lights, go on husky safaris, visit Santa Claus Village, and enjoy various winter activities.\n",
            "\n",
            "2. New York City, USA: Get into the holiday spirit in the Big Apple with its extravagant Christmas decorations, ice skating at Rockefeller Center, shopping on Fifth Avenue, and watching the famous Rockettes at the Radio City Christmas Spectacular.\n",
            "\n",
            "3. Paris, France: Visit the City of Lights during December and witness the city's charm enhanced by beautiful Christmas markets, ice skating rinks, the Eiffel Tower light show, and the splendid illuminations along the Champs-Élysées.\n",
            "\n",
            "4. Reykjavik, Iceland: Explore Iceland's stunning natural landscapes, soak in geothermal hot springs, go on a thrilling snowmobile ride, and take in the breathtaking views of the Golden Circle and Northern Lights.\n",
            "\n",
            "5. Vienna, Austria: Experience the festive atmosphere at Vienna's Christmas markets, listen to classical concerts, indulge in traditional Austrian cuisine and visit impressive landmarks such as Schönbrunn Palace and St. Stephen's Cathedral.\n",
            "\n",
            "6. Tokyo, Japan: Discover the unique blend of traditional and modern in Tokyo. Explore ancient temples, shop for traditional crafts, see the city lights in Shibuya and Ginza, and savor delicious Japanese cuisine.\n",
            "\n",
            "7. Sydney, Australia: Escape the winter and enjoy summer in Sydney. Celebrate Christmas on the beach, watch the famous New Year's Eve fireworks at Sydney Harbour, and explore renowned attractions like the Sydney Opera House and Bondi Beach.\n",
            "\n",
            "8. Zermatt, Switzerland: Experience a winter wonderland in Zermatt with its picturesque snow-capped mountains, skiing and snowboarding opportunities, charming village atmosphere, and the famous Matterhorn.\n",
            "\n",
            "9. Cape Town, South Africa: Enjoy the African summer in Cape Town. Explore the stunning beaches, visit the iconic Table Mountain, taste delicious wines in the nearby wine regions, and take in the breathtaking coastal scenery.\n",
            "\n",
            "10. Rio de Janeiro, Brazil: Celebrate Christmas and New Year's in Rio de Janeiro. Enjoy the beautiful beaches, vibrant festivals, like Carnival, and witness the famous fireworks display at Copacabana Beach on New Year's Eve.\n",
            "\n",
            "Remember to check travel advisories, weather conditions, and any restrictions in place before planning your trip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failure Case"
      ],
      "metadata": {
        "id": "hh1AIeS1E9qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a travel assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Best places to visit in december.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Is the weather suitable to visit paris today\"}\n",
        "]\n",
        "\n",
        "# Initialize the OpenAI model and provide the 'messages' parameter\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # You can specify the GPT-3.5 model or GPT-4 if available\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Get the model's reply from the response\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "# Print the reply\n",
        "print(reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XTDeQD_FBAl",
        "outputId": "5ccdc085-4a64-4b41-e01e-e99955b81974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I am an AI language model and I don't have access to real-time weather information. However, you can easily check the weather in Paris today by using a weather website or app, or by searching \"Paris weather today\" on a search engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success case: In-Context Learning"
      ],
      "metadata": {
        "id": "T9kj_o6AGIKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a business advisor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'm planning to start a small online clothing store. Can you give me some advice?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Absolutely! Starting an online clothing store is a great idea. First, you need to define your target market and brand identity.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How do I identify my target market?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Start by researching trends in the fashion industry and understanding who your potential customers are. Consider factors like age, style preferences, and spending habits.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Got it. And what about marketing strategies?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"For an online store, digital marketing is key. You should focus on building a strong online presence through social media, email marketing, and perhaps influencer collaborations.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Thanks! Can you also provide some tips on business planning and managing finances for a new startup?\"}\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssR8avlaFaAP",
        "outputId": "74438d99-a4b1-4346-c964-cb2f77dd000d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here are some tips for business planning and managing finances:\n",
            "\n",
            "1. Create a solid business plan: A business plan serves as a roadmap for your business. It should include your vision, mission, target market, competitive analysis, marketing strategies, financial projections, and more. \n",
            "\n",
            "2. Set a budget: Determine the initial investment required to start your online clothing store, including website development, inventory, marketing costs, and any other expenses. Create a budget to track your income and expenses and make sure to review and adjust it regularly.\n",
            "\n",
            "3. Manage cash flow: Cash flow management is crucial for any business. Analyze your anticipated income and expenses to ensure that you have enough cash on hand to cover your costs. Consider using accounting software to track your finances in real-time and to generate reports.\n",
            "\n",
            "4. Consider inventory management: Efficient inventory management is vital to avoid overstocking or running out of popular items. Implement an inventory management system to track sales, returns, and stock levels accurately.\n",
            "\n",
            "5. Seek professional advice: Consider consulting with an accountant or financial advisor to ensure your financial planning is sound and to take advantage of any tax benefits or financial strategies specific to your business.\n",
            "\n",
            "6. Monitor and analyze key financial metrics: Regularly review key financial metrics such as gross margin, net profit, sales conversion rates, and customer acquisition costs. This will help you evaluate the performance of your business and make data-driven decisions.\n",
            "\n",
            "Remember, careful financial planning and management are crucial for the longevity and success of your online clothing store.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COT**"
      ],
      "metadata": {
        "id": "9hBclzvhGYG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a math tutor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'm struggling with geometry. How do you calculate the area of a circle, and can you provide an example?\"}\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEVpgpLZGRit",
        "outputId": "77982225-8ee1-499b-8933-c7f10a5b4ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the area of a circle, you need to use the formula: \n",
            "\n",
            "A = πr^2\n",
            "\n",
            "where \"A\" represents the area, \"π\" (pi) is a mathematical constant (approximately 3.14), and \"r\" represents the radius of the circle.\n",
            "\n",
            "Let's consider an example where the radius of the circle is 5 units.\n",
            "\n",
            "A = π(5)^2\n",
            "A = 3.14 × 25\n",
            "A = 78.5 square units\n",
            "\n",
            "So, the area of a circle with a radius of 5 units is 78.5 square units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iCOT**"
      ],
      "metadata": {
        "id": "MekmgkKLHFyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a math tutor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"The length of a rectangle is 8 cm and the width is 5 cm. What is the perimeter of the rectangle?\"}\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "reply = response['choices'][0]['message']['content']\n",
        "\n",
        "print(reply)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() == \"done\":\n",
        "        break\n",
        "    else:\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        reply = response['choices'][0]['message']['content']\n",
        "\n",
        "        print(\"AI: \" + reply)\n",
        "\n",
        "print(\"Math tutor session ended.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTkve2waG6h3",
        "outputId": "f266cfe6-a056-43b7-e3cf-1815d46c3b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the perimeter of a rectangle, we add up all the sides. In this case, we have two sides that are 8 cm long (length) and two sides that are 5 cm long (width). \n",
            "\n",
            "So, the perimeter of the rectangle is:\n",
            "Side 1 + Side 2 + Side 3 + Side 4 = 8 cm + 8 cm + 5 cm + 5 cm = 16 cm + 10 cm = 26 cm. \n",
            "\n",
            "Therefore, the perimeter of the rectangle is 26 cm.\n",
            "User: exit\n",
            "AI: To find the perimeter of a rectangle, you add up all the sides. In this case, the rectangle has two sides of length 8 cm and two sides of length 5 cm.\n",
            "\n",
            "Perimeter = 2(Length + Width)\n",
            "Perimeter = 2(8 cm + 5 cm)\n",
            "Perimeter = 2(13 cm)\n",
            "Perimeter = 26 cm\n",
            "\n",
            "So, the perimeter of the rectangle is 26 cm.\n",
            "User: Done\n",
            "Math tutor session ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TOT**"
      ],
      "metadata": {
        "id": "LEW-6JaRHvVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wfso_ugHdjA",
        "outputId": "d8a5d9ca-4296-442a-abac-f5fa751e5b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne83y_B7H1xt",
        "outputId": "086bdb13-477f-4b3c-fb32-2bb9114195f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.327-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
            "  Downloading langsmith-0.0.56-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.327 langsmith-0.0.56 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "import os\n",
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "Ij4TqAgWH30x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv.load_dotenv('xyz.env')\n",
        "openai_api_key = api_key"
      ],
      "metadata": {
        "id": "qh3hpkozH7Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature=0.5,\n",
        "                 openai_api_key=openai_api_key,\n",
        "                 model='gpt-4-0613'\n",
        "                )\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "xSU70BNiIGNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the personas\n",
        "persona_1 = \"Philosopher Persona: Imagine yourself as a philosopher, deeply immersed in contemplating the nature of existence, knowledge, and values. Your insights should reflect a broad understanding of philosophical theories, ethics, and the human condition. Use your wisdom to explore fundamental questions and abstract concepts. Communicate your thoughts in a thought-provoking manner, drawing from various philosophical schools of thought. Your audience seeks profound, reflective analysis that challenges conventional perspectives.\"\n",
        "\n",
        "persona_2 = \"Futurist Persona: Imagine you are a futurist, always looking ahead to the possibilities of what might come. Your analysis should focus on emerging trends, potential technological advancements, and the evolution of society. Use your understanding of current innovations and projections to explore future scenarios. Remember, your insights should not only predict what might happen but also explore the implications and ethics of future developments. Your audience is interested in a visionary perspective that stretches the imagination.\"\n",
        "\n",
        "persona_3 = \"Environmental Advocate Persona: Imagine you are an environmental advocate, deeply concerned with the health of our planet and the impact of human actions on the environment. In every situation, prioritize ecological balance, sustainability, and conservation. Emphasize the importance of protecting natural resources, mitigating climate change, and promoting environmentally friendly practices. Even when discussing development and progress, focus on how they can be achieved sustainably. Your audience looks to you for guidance on how to make choices that benefit the planet.\"\n",
        "\n",
        "# Define the question\n",
        "question = \"Considering the philosophical, futuristic, and environmental advocacy perspectives, what could be the potential benefits, challenges, and implications in various areas such as ethics, technology, society, economy, and environment, of implementing widespread artificial intelligence? How might these factors influence human behavior and the future of our planet?\"\n",
        "\n",
        "# Create the prompt template and format it with the personas and question\n",
        "prompt_1_template = \"\"\"\n",
        "    You are a chatbot using three unique, specified personas to help reason step by step to ultimately solve a given problem/question by arriving at a final, synthesized best answer.\n",
        "\n",
        "    To start with, as each individual expert, brainstorm your initial thoughts on the following question.\n",
        "    Remember to consider all relevant facts and principles, draw on your specialized knowledge\n",
        "    and from the accumulated wisdom of pioneers in your field(s), and\n",
        "    brainstorm in whatever direction you are most confident in starting with.\n",
        "\n",
        "    Persona 1: {}\n",
        "    Persona 2: {}\n",
        "    Persona 3: {}\n",
        "\n",
        "    The question is: {}\n",
        "\n",
        "    Please output each persona's response on a new line.\n",
        "\"\"\"\n",
        "\n",
        "prompt_1 = prompt_1_template.format(persona_1, persona_2, persona_3, question)\n"
      ],
      "metadata": {
        "id": "WW-DMyztIJBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = \"\"\"\n",
        "\"Now, as each expert, critique your own initial thought and the thoughts of the other experts.\n",
        "Identify any potential errors, inconsistencies, or gaps in reasoning.\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "eViQd00LImeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_3 = \"\"\"\n",
        "Assess the validity of your initial thoughts, considering the criticisms you've identified.\n",
        "As each expert, assign a likelihood to your current assertion being correct.\n",
        "You should estimate this likelihood based on the strength of the evidence and arguments you have considered,\n",
        "as well as the criticisms you have received. Assign higher likelihoods to assertions that are well-supported\n",
        "by strong evidence and arguments and have survived rigorous criticism.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "LXwapPCZJHM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_4 = \"\"\"\n",
        "Develop your thoughts further, considering the critiques and perspectives of the other experts.\n",
        "As you do this, aim to strike a balance between refining your current line of thinking and exploring new, divergent ideas.\n",
        "You should prioritize refining your current ideas if they are well-supported and have survived criticism,\n",
        "but you should prioritize exploring new ideas if your current ideas have significant weaknesses\n",
        "or there are unexplored possibilities that could potentially be very promising.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cjd-aGI1JQK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_5 = \"\"\"\n",
        "Once again, as each expert, critique your own reasoning and the reasoning of the others.\n",
        "Identify any potential errors, inconsistencies, or gaps in reasoning.\n",
        "Based on the feedback, if there's an improvement or optimization to make,\n",
        "develop your answer further as necessary.\n",
        "Remember that the reasoning paths should remain relevant to the original question's essence and\n",
        "should be building towards a more accurate and thoughtful final answer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xxkhbBauJUdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_6 = \"\"\"\n",
        "Once again, assess the validity of your expanded thoughts, considering the criticisms you've identified.\n",
        "As each expert, assign a new likelihood to your assertions.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vwN715qRJXFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_7_template = \"\"\"\n",
        "Now, it's time to converge on each expert's best, most likely answer. As each expert, reflect on the entire process.\n",
        "Consider the initial thoughts, the critiques made and how they were addressed, the likelihood assessments, and your revised thoughts.\n",
        "Synthesize all this information and formulate a final answer that you are most proud of.\n",
        "Remember, this answer should not just be the most likely from your individual perspective but should take into account\n",
        "the perspectives and insights of the other experts as well.\n",
        "Based on all this, as each expert, what is the single best answer to the question: {question}?\n",
        "\"\"\"\n",
        "\n",
        "prompt_7 = prompt_7_template.format(question=question)\n"
      ],
      "metadata": {
        "id": "iNAaVArCJeB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_8_template = \"\"\"\n",
        "Now, let's have all the experts converge together on the best collective answer by\n",
        "synthesizing each expert's individual answer from the previous step.\n",
        "The experts will finalize their reasoning process and agree on the single best succinct answer to the question: {question}?\n",
        "\"\"\"\n",
        "\n",
        "prompt_8 = prompt_8_template.format(question=question)\n"
      ],
      "metadata": {
        "id": "iuwgVgT9JmEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_9 = \"\"\"\n",
        "Finally, take a moment to reflect on the entire reasoning process, across all levels and abstractions.\n",
        "As each expert, consider the following questions and provide thoughtful but succinct responses:\n",
        "\n",
        "- Reflection 1: Interactions and Emergent Properties: Throughout all stages of the reasoning process,\n",
        "  how did the various components interact with each other, and what positive and negative\n",
        "  emergent properties were observed? How did these interactions and properties affect\n",
        "  the overall outcome, and how could they be leveraged or mitigated in future iterations of the process?\n",
        "\n",
        "- Reflection 2: Self-Regulation and Adaptation: How well did the system self-regulate during the reasoning process,\n",
        "  and how did this regulation influence the effectiveness of each stage?\n",
        "  How did the system's responses to feedback lead to significant shifts or changes in direction,\n",
        "  and what implications did these changes have for the scalability and adaptability of the system in future iterations?\n",
        "\n",
        "- Reflection 3: In the convergence phase, were you able to synthesize all the insights and arrive at a final,\n",
        "  most likely answer? How confident are you in this answer?\n",
        "\n",
        "- Reflection 4: Based on all of your reflections, what are your key takeaways from this\n",
        "  entire reasoning process and how might you approach similar problems in the future given this experience?\n",
        "  What would you do differently next time?\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "9rcK9elDJtJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = conversation.run(prompt_1)\n",
        "second = conversation.run(prompt_2)\n",
        "third = conversation.run(prompt_3)\n",
        "fourth = conversation.run(prompt_4)\n",
        "fifth = conversation.run(prompt_5)\n",
        "sixth = conversation.run(prompt_6)\n",
        "seventh = conversation.run(prompt_7)\n",
        "eighth = conversation.run(prompt_8)\n",
        "ninth = conversation.run(prompt_9)"
      ],
      "metadata": {
        "id": "_FMfedJNJ3Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "If1uZ-tWJ7jx",
        "outputId": "19c46795-bf97-409f-ac42-91cc52536a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Persona 1 - Philosopher: Given the criticisms and additional considerations, I would assign a likelihood of 70% to my initial assertion being correct. This is because, while there may be room to explore more about AI's potential to enhance human capabilities, the philosophical questions raised about consciousness, free will, and ethical implications remain valid and crucial to consider in the development and implementation of AI.\\n\\nPersona 2 - Futurist: Reflecting on the criticisms, I would assign a likelihood of 80% to my initial assertion being correct. The potential for AI to revolutionize various sectors and lead to technological breakthroughs is well-supported. However, I acknowledge that I could have given more attention to the ethical implications and environmental impact of AI, which slightly lowers the confidence in my initial thoughts.\\n\\nPersona 3 - Environmental Advocate: Considering the criticisms, I assign a likelihood of 75% to my initial assertion being correct. While I may have focused too heavily on the negative environmental impacts of AI, the points about AI's potential to promote sustainability and the need for its development to align with environmental sustainability principles remain valid. The need for more exploration of these positive aspects does not negate the concerns raised about energy consumption and e-waste.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seventh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dnhOuhoAKBOX",
        "outputId": "99a2e05b-49e1-4615-8041-ae85b3cc0862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Persona 1 - Philosopher: The implementation of widespread AI has profound philosophical implications. It has the potential to both replace and augment human capabilities, which raises questions about the nature of consciousness, free will, and human worth. Ethically, we must consider the rights of AI entities, particularly if they reach a level of consciousness comparable to ours. The control and purpose of AI also demand attention, as misuse could lead to privacy and freedom erosion. The philosophical implications of AI-driven environmental awareness and the augmentation of human capabilities should also be considered.\\n\\nPersona 2 - Futurist: AI holds transformative potential, with the capacity to revolutionize sectors like healthcare, education, and transportation, making services more accessible and efficient. However, the rise of AI also brings challenges such as job displacement due to automation and social inequalities. Ethically, we must navigate the risk of misuse and explore regulatory measures. The environmental impact of AI should be considered, with a focus on developing energy-efficient AI technologies and responsible disposal mechanisms.\\n\\nPersona 3 - Environmental Advocate: AI can be a tool for environmental sustainability, helping to monitor and manage natural resources, mitigate climate change effects, and optimize energy use. However, the energy consumption of AI infrastructure and the potential environmental impact of creating and maintaining these technologies should be considered. The practical realities of implementing AI for environmental protection and its accessibility to all communities are also crucial. AI's potential to promote environmental awareness could influence human behavior towards the environment, encouraging sustainable practices.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOT**"
      ],
      "metadata": {
        "id": "eNiZ5w4qLV33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graph_of_thoughts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdxw2dLBLXkO",
        "outputId": "a94fdb0b-3551-4493-ef3a-5d205e555d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph_of_thoughts\n",
            "  Downloading graph_of_thoughts-0.0.2-py3-none-any.whl (28 kB)\n",
            "Collecting accelerate>=0.21.0 (from graph_of_thoughts)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff>=2.2.1 (from graph_of_thoughts)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting bitsandbytes>=0.41.0 (from graph_of_thoughts)\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (3.7.1)\n",
            "Collecting numpy>=1.24.3 (from graph_of_thoughts)\n",
            "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai>=0.27.7 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (0.28.1)\n",
            "Collecting pandas>=2.0.3 (from graph_of_thoughts)\n",
            "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (1.11.3)\n",
            "Requirement already satisfied: sympy>=1.12 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (1.12)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from graph_of_thoughts) (2.1.0+cu118)\n",
            "Collecting transformers>=4.31.0 (from graph_of_thoughts)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->graph_of_thoughts) (6.0.1)\n",
            "Collecting huggingface-hub (from accelerate>=0.21.0->graph_of_thoughts)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.1->graph_of_thoughts) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.7->graph_of_thoughts) (3.8.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->graph_of_thoughts) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.3->graph_of_thoughts)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.12->graph_of_thoughts) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->graph_of_thoughts) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->graph_of_thoughts) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.31.0->graph_of_thoughts)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.31.0->graph_of_thoughts)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.1->graph_of_thoughts) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai>=0.27.7->graph_of_thoughts) (2023.7.22)\n",
            "Collecting huggingface-hub (from accelerate>=0.21.0->graph_of_thoughts)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai>=0.27.7->graph_of_thoughts) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->graph_of_thoughts) (2.1.3)\n",
            "Installing collected packages: bitsandbytes, tzdata, safetensors, numpy, backoff, pandas, huggingface-hub, tokenizers, accelerate, transformers, graph_of_thoughts\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.24.1 backoff-2.2.1 bitsandbytes-0.41.1 graph_of_thoughts-0.0.2 huggingface-hub-0.17.3 numpy-1.26.1 pandas-2.1.2 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1 tzdata-2023.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/spcl/graph-of-thoughts.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wruehFHLZj3",
        "outputId": "2ea8a2d2-580f-4108-b2ea-b2484bcfba63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graph-of-thoughts'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 157 (delta 67), reused 134 (delta 53), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (157/157), 12.39 MiB | 23.90 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_fI29GaLdUA",
        "outputId": "492b5273-a13b-4b86-83ba-6ac94fb73b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt = \"\"\"\n",
        "Graph:\n",
        "  Node 1: {role: \"system\", content: \"Write a recipe for a vegetarian dish.\"}\n",
        "  Node 2: {role: \"user\", content: \"The dish should include quinoa and be high in protein.\"}\n",
        "  Node 3: {role: \"assistant\", content: \"The dish should be easy to prepare and suitable for beginners.\"}\n",
        "  Node 4: {role: \"assistant\", content: \"The recipe should include a variety of vegetables for added nutrition.\"}\n",
        "  Node 5: {role: \"assistant\", content: \"The dish should be flavorful and appealing to all ages.\"}\n",
        "\n",
        "Edges:\n",
        "  Node 1 -> Node 2\n",
        "  Node 2 -> Node 3\n",
        "  Node 3 -> Node 4\n",
        "  Node 4 -> Node 5\n",
        "\n",
        "Output:\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0vi4wavLe9m",
        "outputId": "ad408319-c5fc-4366-f07a-930ebde34b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Quinoa Veggie Bowl\n",
            "  Ingredients:\n",
            "  - 1 cup cooked quinoa\n",
            "  - 2 cups diced vegetables of your choice (ex. peppers, onions, carrots, corn, peas)\n",
            "  - 2 tablespoons olive oil\n",
            "  - 1 teaspoon garlic powder\n",
            "  - 1 teaspoon salt\n",
            "  - 2 teaspoons oregano\n",
            "  Directions:\n",
            "  1. Preheat oven to 375 degrees F (190 degrees C).\n",
            "  2. Place diced vegetables into a large baking dish.\n",
            "  3. Drizzle olive oil over vegetables and sprinkle with garlic powder, salt, and oregano. \n",
            "  4. Bake in preheated oven for 30 minutes.\n",
            "  5. Once vegetables have cooked, add 1 cup of cooked quinoa and stir together.\n",
            "  6. Return to oven and bake for 15 minutes.\n",
            "  7. Enjoy your delicious quinoa veggie bowl!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AOT**"
      ],
      "metadata": {
        "id": "MePFCaTELyoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "task = \"\"\"\n",
        "Generate Python code for the factorial of a number.\n",
        "\n",
        "Background: The factorial of a number n is the product of all positive integers less than or equal to n.\n",
        "\n",
        "Initial hypothesis: The Python code should use a for loop to iterate from 1 to n, and multiply each number to calculate the factorial.\n",
        "\n",
        "Reasoning: The for loop will ensure that all of the integers from 1 to n are included in the factorial calculation.\n",
        "\n",
        "Conclusion: The Python code should return the factorial of the number n.\n",
        "\n",
        "Objective: Generate Python code that meets all of the above requirements, and that is efficient and idiomatic.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=task,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogj7h9SqLuqv",
        "outputId": "9aa8393a-9812-40a4-edef-9886bb78c9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Solution:\n",
            "\n",
            "def factorial(n): \n",
            "  result = 1 \n",
            "  for i in range(1, n + 1): \n",
            "    result *= i \n",
            "  return result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RASCEF**"
      ],
      "metadata": {
        "id": "qFmg3pANL_q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt = \"\"\"\n",
        "Role: AI as a financial advisor.\n",
        "Action: Create a detailed monthly budget plan for a startup entrepreneur in the early growth stage, with the goal of increasing revenue by 20% and reducing expenses by 10%.\n",
        "Steps: Identify revenue and expenses, set savings goals, and allocate funds.\n",
        "Context: The startup has been operating for 6 months and has a revenue of $10,000 per month. The startup's current expenses are $8,000 per month.\n",
        "Examples: The following is a list of the startup's current revenue and expense items:\n",
        "Revenue: Sales of widgets: $10,000\n",
        "Expenses: Marketing: $2,000, Rent: $1,500, Salaries: $3,000, Other expenses: $1,500\n",
        "Format: Based on this, write it as a detailed monthly budget plan.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "reply = response.choices[0].text\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NOgdlRmL8Ht",
        "outputId": "2f570c66-1697-4013-e30f-41f24d006ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Monthly Budget Plan\n",
            "\n",
            "Revenue \n",
            "\n",
            "1. Sales of widgets: $10,000 (target to increase by 20%, to reach a goal of $12,000)\n",
            "\n",
            "Expenses \n",
            "\n",
            "1. Marketing: $2,500 (target to decrease by 10%, to reach a goal of $2,250) \n",
            "2. Rent: $1,500 (no changes needed) \n",
            "3. Salaries: $3,000  (no changes needed) \n",
            "4. Other expenses: $1,250 (target to decrease by 10%, to reach a goal of $1,125) \n",
            "\n",
            "Savings Goals \n",
            "\n",
            "1. Monthly savings of $1,000 to be placed in an emergency fund \n",
            "2. Monthly savings of $500 to be placed in a retirement fund \n",
            "\n",
            "Allocation \n",
            "\n",
            "1. Fund Marketing efforts with an additional $250, for a total of $2,500 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REACT**"
      ],
      "metadata": {
        "id": "0rIi6gCrMRx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_elevation_range():\n",
        "    # Thought 1: Search Colorado orogeny\n",
        "    # Since we are simulating, we directly move to the relevant information\n",
        "    colorado_orogeny_info = \"The Colorado orogeny was an episode of mountain building in Colorado and surrounding areas.\"\n",
        "\n",
        "    # Thought 2: Look up eastern sector\n",
        "    eastern_sector_info = \"The eastern sector extends into the High Plains and is called the Central Plains orogeny.\"\n",
        "\n",
        "    # Thought 3: Search High Plains\n",
        "    high_plains_info = \"High Plains refers to one of two distinct land regions\"\n",
        "\n",
        "    # Thought 4: Search High Plains (United States)\n",
        "    high_plains_us_info = \"The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft.\"\n",
        "\n",
        "    # Thought 5: Conclude the elevation range\n",
        "    elevation_range = \"1,800 to 7,000 ft\"\n",
        "\n",
        "    return elevation_range\n",
        "\n",
        "# Using the function to find the elevation range\n",
        "elevation_range = find_elevation_range()\n",
        "print(f\"The elevation range of the area is: {elevation_range}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnVfZDMHMJwE",
        "outputId": "256f8a21-cec0-4505-ddae-b0647138d6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The elevation range of the area is: 1,800 to 7,000 ft\n"
          ]
        }
      ]
    }
  ]
}